{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "3856b16e-67cf-4070-ad0e-71ac598be8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(tibble)\n",
    "library(Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56ff89-32ac-4e08-a9e0-d5a4939981a2",
   "metadata": {},
   "source": [
    "# 4. Matrix completion\n",
    "\n",
    "## Outline\n",
    "Suppose $Y\\in\\mathbb R^{n\\times d}$. Introduce missing values by projecting to domain $\\Omega$, taken to be random samples from $Y$. We have the matrix completion problem,\n",
    "$$\n",
    "\\min_X \\left\\{\\frac{1}{2}\\|\\mathcal P_\\Omega(Y)-\\mathcal P_\\Omega(X)\\|_2^2+\\lambda\\|X\\|_1\\right\\}\n",
    "$$\n",
    "The projection operator is simply element-wise multiplication by the indicator function, $\\mathcal P_{\\Omega}(X):=X\\mathbf{1}_\\Omega$. $\\|A\\|_p$ denotes the $p$-Schatten norm is $A$ is a matrix and $l^p$ norm if it is a vector.\n",
    "\n",
    "The gradient of the differentiable part of this loss function is\n",
    "$$\n",
    "g(X):=\\mathcal P_\\Omega Y-\\mathcal P_\\Omega X.\n",
    "$$\n",
    "Proximal gradient descent has us computing\n",
    "$$\n",
    "X^+ = \\text{prox}_{t\\lambda}(X-t g(X)).\n",
    "$$\n",
    "Notice that the gradient has Lipschitz constant $1$. So, we are guaranteed convergence with  \n",
    "$$\n",
    "\\begin{align*}\n",
    "X^+ &= \\text{prox}_{\\lambda}(X-\\mathcal P_\\Omega X+ \\mathcal P_\\Omega Y)\\\\\n",
    "&=\\text{prox}_{\\lambda}(\\mathcal P_{\\Omega^c} X+ \\mathcal P_\\Omega Y).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## Proximal operator for nuclear norm\n",
    "**Prop** The prox operator, \n",
    "$$\n",
    "\\text{prox}_{\\lambda\\|\\cdot\\|_1}(X)=\\arg\\min_Z\\left(\\frac{1}{2}\\|X-Z\\|_2^2+\\lambda \\|Z\\|_1\\right)\n",
    "$$\n",
    "is given by SVD with the singular values being the soft-thresholded at level $\\lambda$,\n",
    "$$\n",
    "U\\text{diag}(\\max(\\Sigma_{ii}-\\lambda,0))V^T\n",
    "$$\n",
    "\n",
    "**proof.** Start with SVD decomposition,\n",
    "$$\n",
    "X=U\\Sigma V^T.\n",
    "$$\n",
    "Note that \n",
    "$$\n",
    "\\text{prox}_{\\lambda\\|\\cdot\\|_1}(U\\Sigma V^T) = U\\text{prox}_{\\lambda\\|\\cdot\\|_1}(\\Sigma)V^T.\n",
    "$$\n",
    "because Schatten norms are unitary invariant/they depend only on singular values. Then, defining $\\sigma:=\\{\\Sigma_{ii}|i\\in[1, d]\\}$,\n",
    "$$\n",
    "\\text{prox}_{\\lambda\\|\\cdot\\|_1}(\\sigma) = \\arg\\min_z\\left(\\frac{1}{2}\\|\\sigma-z\\|_2^2+\\lambda \\|z\\|_1\\right)\n",
    "$$\n",
    "is now the proximal operator of the $l^1$ norm. Subgradient optimality reads\n",
    "$$\n",
    "\\begin{align*}\n",
    "0&\\in (\\sigma-z)+\\lambda\\partial\\|z\\|_1\\\\\n",
    "z-\\sigma&\\in \\lambda\\partial\\|z\\|_1\\\\\n",
    "z-\\sigma&\\in \\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\lambda & z>0\\\\\n",
    "      -\\lambda & z<0 \\\\\n",
    "      [-\\lambda,\\lambda] & z=0\\\\\n",
    "\\end{array}\n",
    "\\right\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "which can be massaged into the soft-thresholding form,\n",
    "$$\n",
    "\\text{prox}_{\\lambda\\|\\cdot\\|_1}(\\sigma)=\\text{sign}(\\sigma)(|\\sigma|-\\lambda)_+\n",
    "$$\n",
    "Since singular values are positive, this simply becomes\n",
    "$$\n",
    "\\text{prox}_{\\lambda\\|\\cdot\\|_1}(\\sigma)=(\\sigma-\\lambda)_+\n",
    "$$\n",
    "Introducing the unitaries $U$ and $V$ back,\n",
    "$$\n",
    "\\text{prox}_{\\lambda\\|\\cdot\\|_1}(X)=U\\text{diag}((\\sigma-\\lambda)_+)V^T_{\\quad \\square}\n",
    "$$\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "Let's generate random $n\\times d$ Gaussian matrix with rank $k$. We do this by taking $k$ linear combinations of the outer product of random vectors of length $n$ and $d$. For finite random matrices, there is a finite probability of linear dependence among elements of this combination so we need to check that the desired rank is indeed achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "07e15917-43a0-4c5d-a971-a1868cf16008",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data <- function(n=200, d=100, k=2, seed =42) \n",
    "{\n",
    "    set.seed(seed)\n",
    "    X <- rnorm(n)%o%rnorm(d)\n",
    "    while((rankMatrix(X)[1])!=k)\n",
    "        {for(rank_idx in seq(1, k-1)){X <- X +rnorm(n)%o%rnorm(d)}}\n",
    "    mask <- matrix(as.integer(runif(n*d, 0, 2)), nrow=n, ncol=d)\n",
    "    return(list(X=X, Y=mask*X, mask=mask))\n",
    "}\n",
    "data <- generate_data(n=100, d=20, k=5, seed =58)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3dbb0-1e9f-45d9-afa3-67ffe5078e13",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "7c11c40b-8cc2-4c81-8b50-decd90d4602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear.norm <- function(X){sum(svd(X)$d)}\n",
    "l2.norm <- function(a) {sqrt(sum(a*a))}\n",
    "prox.nuclear <- function(X, lam)\n",
    "{\n",
    "    usv <- svd(X)\n",
    "    sigma <-  pmax(usv$d-lam, 0)\n",
    "    return(usv$u%*%(sigma*diag(length(sigma)))%*%t(usv$v))\n",
    "}\n",
    "loss.matrix_comp <- function(X, y, mask, lam){0.5*sum((X*mask-y)**2)+lam*nuclear.norm(X)}\n",
    "gd_step.matrix_comp <- function(X, Y, t, lam, mask) {prox.nuclear(X+t*(Y-X*mask), lam)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "3c9ef05b-9e02-4a6a-b21f-91e2df9ed275",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.matrix_comp <- function(Y, mask, X_true=NULL, lam=0.1, max_iter=2000, t=1)\n",
    "{\n",
    "    d <- dim(Y)[2]\n",
    "    n <- dim(Y)[1]\n",
    "    X <- matrix(rnorm(d*n), nrow=n, ncol=d)\n",
    "    loss <- NULL\n",
    "    error1 <- NULL\n",
    "    error2 <- NULL\n",
    "    iter <- 0\n",
    "    for(iter in seq(1, max_iter))\n",
    "    {\n",
    "        X <- gd_step.matrix_comp(X, Y, t, lam, mask)\n",
    "        loss <- c(loss, loss.matrix_comp(X, Y, mask, lam))\n",
    "        if(!is.null(X_true))\n",
    "        {\n",
    "            sing_true <- svd(X_true)$d\n",
    "            sing_pred <- svd(X)$d\n",
    "            k <- rankMatrix(X_true)\n",
    "            error1 <- c(error1, l2.norm((sing_true-sing_pred)[1:k]))\n",
    "            error2 <- c(error2, l2.norm(sing_true[-1:-k]-sing_pred[-1:-k]))\n",
    "        }\n",
    "    }\n",
    "    return(list(X_pred=X, loss=loss,  error1=error1, error2=error2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "cc4d939f-e6a1-401c-81aa-17ed9d811fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.matrix_comp <- fit.matrix_comp(Y=data$Y, mask=data$mask, X_true=data$X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63803cd6-26f4-45f3-ad13-3cfeb37e0b54",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We check the correctness of the model by comparing (via $l^2$ norm) the singular values of the model output and the true matrix. A rank $k$ matrix will have $k$ non-zero singular values. We compare both the largest $k$ singular values and the smallest $d-k$ singular values of the model output to that of the true matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "744ba1ef-3a02-4021-9265-32fd7ed095ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- tibble(n.iter = 1:length(model.matrix_comp$error1) ,\n",
    "loss = model.matrix_comp$loss ,\n",
    "error.rank = model.matrix_comp$error1,\n",
    "error.global = model.matrix_comp$error2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "12668fea-cf8c-4aa4-b5b8-bd70d8dbff42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf('Matconv4.pdf', width=10, height =6)\n",
    "\n",
    "ggplot(data=df, aes(x=n.iter)) +\n",
    "geom_line(aes(y=loss , color='blue'), lwd=1.5) +\n",
    "geom_line(aes(y=error.rank , color='red'), lwd=1.5) +\n",
    "geom_line(aes(y=error.global , color='magenta'), lwd=1.5) +\n",
    "scale_color_discrete(\n",
    "name = \"\", labels = c(\"loss\", \"error in largest k singular vals\", \"error in smallest d-k singular vals\")) +\n",
    "ylab('loss | error') +\n",
    "xlab('epoch ') +\n",
    "theme_bw() +\n",
    "theme(legend.position='bottom', text = element_text(size = 16))\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3cfb5-1ab2-4569-81c7-ca222042f92e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
